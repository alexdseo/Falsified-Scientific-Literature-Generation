{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f29c90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tika import parser\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import jsonlines\n",
    "import random\n",
    "import re\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b852023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making 500 text files\n",
    "file = open('falsified_text_fromBIK.jsonl')\n",
    "filename = 0\n",
    "\n",
    "for i in file:\n",
    "    res = json.loads(i)\n",
    "    res = res[\"gens_article\"]\n",
    "    res = str(res)\n",
    "    res = res.replace(\"[\",\"\")\n",
    "    res = res.replace(\"]\",\"\")\n",
    "    \n",
    "    with open(\"../fake_text/fake_text/\" + str(filename) + '.txt', 'w',encoding=\"utf-8\") as f:\n",
    "        f.write(res)\n",
    "        \n",
    "    filename = filename + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71b03351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "txt_files = glob.glob(\"fake_text/*.txt\")\n",
    "txt_files = sorted(txt_files, key=lambda x: int(re.match('\\D*(\\d+)', x).group(1)))\n",
    "\n",
    "print(len(txt_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0737f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Authors', 'Title', 'Citation', 'DOI', 'Year', 'Month',\n",
       "       '0', '1', '2', '3', 'FINDINGS', 'Reported', 'Correction Date',\n",
       "       'Retraction', 'Correction', 'No Action', 'SUM \\nCompleted', 'URL',\n",
       "       'Home Site', 'Lab Size', 'Pub Rate', 'Other Journals',\n",
       "       'First Author Affiliation', 'First Author Career Duration',\n",
       "       'First Author Degree', 'First Author Degree Area', 'university_name',\n",
       "       'world_rank_x', 'country_x', 'national_rank', 'quality_of_education',\n",
       "       'alumni_employment', 'quality_of_faculty', 'publications', 'influence',\n",
       "       'citations_x', 'broad_impact', 'patents', 'score', 'year_x',\n",
       "       'world_rank_y', 'country_y', 'teaching', 'international', 'research',\n",
       "       'citations_y', 'income', 'total_score', 'num_students',\n",
       "       'student_staff_ratio', 'international_students', 'female_male_ratio',\n",
       "       'year_y', 'city_ascii', 'state_id', 'state_name', 'county_fips',\n",
       "       'county_name', 'lat', 'lng', 'population', 'density', 'source',\n",
       "       'military', 'incorporated', 'timezone', 'ranking', 'zips', 'county',\n",
       "       'labor_force', 'employed', 'unemployed', 'rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bik_df = pd.read_csv('../text_extraction/Bik_v2.tsv', sep='\\t', encoding='unicode-escape')\n",
    "bik_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5be5431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file = []\n",
    "\n",
    "for i in range(72):\n",
    "\n",
    "    with open(txt_files[i+428]) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    newinput ={}\n",
    "    \n",
    "    newinput[\"title\"] = str(bik_df['Title'][i])\n",
    "    newinput['warc_date'] = '20220328'\n",
    "    newinput[\"article\"]= str(lines)\n",
    "    newinput[\"inst_index\"] = str(random.randint(9999,100000)) #radom 5 figure number\n",
    "    newinput[\"domain\"] = str(bik_df['Citation'][i])\n",
    "    newinput[\"url\"] = bik_df['URL'][i]\n",
    "    newinput[\"summary\"] = \"\" #Blank until we figure out the abstract stuff\n",
    "    newinput['authors'] = str([bik_df['Authors'][i]])\n",
    "    newinput['date'] =  '03-28-' + str(bik_df['Year'][i])  #Needs actual published date in form of 'M-D-2022' but try with today + publushed year\n",
    "    newinput[\"split\"] = \"test\"\n",
    "    newinput[\"label\"] = \"machine\"\n",
    "    newinput[\"status\"] = \"succcess\"\n",
    "    \n",
    "    master_file.append(newinput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b555bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "pdf_files = glob.glob('../text_extraction/PDFs'+\"/*.pdf\")\n",
    "pdf_files = sorted(pdf_files, key=lambda x: int(re.match('\\D*(\\d+)', x).group(1)))\n",
    "\n",
    "print(len(pdf_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d6b412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#human written text\n",
    "#master_file = []\n",
    "\n",
    "for i in range(len(pdf_files)):\n",
    "\n",
    "    parsed_file = parser.from_file(pdf_files[i])\n",
    "    extracted_text = parsed_file[\"content\"].strip()\n",
    "    \n",
    "    newinput ={}\n",
    "    \n",
    "    newinput[\"title\"] = str(bik_df['Title'][i])\n",
    "    newinput['warc_date'] = '20220328'\n",
    "    newinput[\"text\"]= str(extracted_text) #+ ' [CLS]'\n",
    "    newinput[\"inst_index\"] = str(random.randint(9999,100000)) #radom 5 figure number\n",
    "    newinput[\"domain\"] = str(bik_df['Citation'][i])\n",
    "    newinput[\"url\"] = bik_df['URL'][i]\n",
    "    newinput[\"summary\"] = \"\" #Blank until we figure out the abstract stuff\n",
    "    newinput['authors'] = str([bik_df['Authors'][i]])\n",
    "    newinput['date'] =  '03-28-' + str(bik_df['Year'][i])  #Needs actual published date in form of 'M-D-2022' but try with today + publushed year\n",
    "    newinput[\"split\"] = \"test\"\n",
    "    newinput[\"label\"] = \"human\"\n",
    "    newinput[\"status\"] = \"succcess\"\n",
    "    \n",
    "    master_file.append(newinput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd80a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94dfd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mnh_text_disc.jsonl','w', encoding='utf-8') as f:\n",
    "    for item in master_file:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
